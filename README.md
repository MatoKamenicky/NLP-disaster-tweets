# NLP with Disaster Tweets

This repository contains my solution for the [Kaggle NLP with Disaster Tweets competition](https://www.kaggle.com/competitions/nlp-getting-started),  
where the goal is to classify tweets as describing real disasters or not.

## ðŸ“Œ Overview
- **Dataset**: tweets labeled as disaster or non-disaster.
- **Task**: Binary classification.
- **Model**:
  - Base: [BERTweet](https://huggingface.co/vinai/bertweet-base) - BERT-base model pretrained on English Tweets
  - Custom head:
  ```
  Linear(embedding_dim â†’ hidden_dim1) â†’ Dropout(0.3) â†’ ReLU  
  â†’ Linear(hidden_dim1 â†’ hidden_dim2) â†’ Dropout(0.2)  
  â†’ Linear(hidden_dim2 â†’ output_dim)
  ```

## ðŸ“˜ Notebook
The notebook [NLP-disaster-tweets.ipynb](github.com/MatoKamenicky/NLP-disaster-tweets/blob/main/NLP-disaster-tweets.ipynb) contains the full solution pipeline, including:
- Data loading
- Exploratory Data Analysis (EDA)
- Tokenization
- Model building
- Training loop
- Model evaluation
- Kaggle submission file creation

## ðŸ“Š Results
- Best accuracy: 82.837%
- Predictions are generated in submission.csv format for direct Kaggle upload
- Additional preprocessing (removing URLs, special characters, etc.) did **not** improve performance â€” best results were achieved with simple tokenization only.
